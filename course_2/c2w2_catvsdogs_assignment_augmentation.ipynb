{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path_cats_and_dogs = f\"{getcwd()}/datasets/cats-and-dogs.zip\"\n",
    "# shutil.rmtree('datasets')\n",
    "\n",
    "local_zip = path_cats_and_dogs\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('datasets')\n",
    "zip_ref.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('datasets/PetImages/Cat/')))\n",
    "print(len(os.listdir('datasets/PetImages/Dog/')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Use os.mkdir to create your directories\n",
    "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
    "data_dir = 'datasets/cats-v-dogs'\n",
    "\n",
    "try:\n",
    "    #YOUR CODE GOES HERE\n",
    "    # shutil.rmtree('datasets/cats-v-dogs')\n",
    "    os.mkdir('datasets/cats-v-dogs')\n",
    "    os.mkdir('datasets/cats-v-dogs/training')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing')\n",
    "    os.mkdir('datasets/cats-v-dogs/training/cats/')\n",
    "    os.mkdir('datasets/cats-v-dogs/training/dogs/')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing/cats/')\n",
    "    os.mkdir('datasets/cats-v-dogs/testing/dogs/')\n",
    "except OSError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 666.jpg Omitted because zero file length\n",
      "\n",
      "Dataset Length: 12500\n",
      "\n",
      "Test Dataset Length: 11250\n",
      "\n",
      "Training Dataset Length: 1250\n",
      "File: 11702.jpg Omitted because zero file length\n",
      "\n",
      "Dataset Length: 12500\n",
      "\n",
      "Test Dataset Length: 11250\n",
      "\n",
      "Training Dataset Length: 1250\n"
     ]
    }
   ],
   "source": [
    "# Write a python function called split_data which takes\n",
    "# a SOURCE directory containing the files\n",
    "# a TRAINING directory that a portion of the files will be copied to\n",
    "# a TESTING directory that a portion of the files will be copie to\n",
    "# a SPLIT SIZE to determine the portion\n",
    "# The files should also be randomized, so that the training set is a random\n",
    "# X% of the files, and the test set is the remaining files\n",
    "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
    "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
    "# and 10% of the images will be copied to the TESTING dir\n",
    "# Also -- All images should be checked, and if they have a zero file length,\n",
    "# they will not be copied over\n",
    "#\n",
    "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
    "# os.path.getsize(PATH) gives you the size of the file\n",
    "# copyfile(source, destination) copies a file from source to destination\n",
    "# random.sample(list, len(list)) shuffles a list\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "# YOUR CODE STARTS HERE\n",
    "    files = []\n",
    "    for file_name in os.listdir(SOURCE):\n",
    "        file = SOURCE + file_name\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(file_name)\n",
    "        else:\n",
    "            print(f'File: {file_name} Omitted because zero file length')\n",
    "    dataset_length = len(files)\n",
    "    train_length = int(dataset_length * SPLIT_SIZE)\n",
    "    test_length = dataset_length - train_length\n",
    "    print(f'\\nDataset Length: {dataset_length}')\n",
    "    print(f'\\nTest Dataset Length: {train_length}')\n",
    "    print(f'\\nTraining Dataset Length: {test_length}')\n",
    "    randomized_set = random.sample(files, dataset_length)\n",
    "    train_dataset = randomized_set[0:train_length]\n",
    "    test_dataset = randomized_set[-test_length:]\n",
    "    for file_name in train_dataset:\n",
    "        copyfile(SOURCE+file_name, TRAINING+file_name)\n",
    "    for file_name in test_dataset:\n",
    "        copyfile(SOURCE+file_name, TESTING+file_name)\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"datasets/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"datasets/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"datasets/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"datasets/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"datasets/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"datasets/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250\n",
      "11250\n",
      "1250\n",
      "1250\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('datasets/cats-v-dogs/training/cats/')))\n",
    "print(len(os.listdir('datasets/cats-v-dogs/training/dogs/')))\n",
    "print(len(os.listdir('datasets/cats-v-dogs/testing/cats/')))\n",
    "print(len(os.listdir('datasets/cats-v-dogs/testing/dogs/')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "# USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "model = tf.keras.models.Sequential([\n",
    "# YOUR CODE HERE\n",
    "    # 150x150 resolution and last channel with 3 for RGB value from 0 to 255 each\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = 'datasets/cats-v-dogs/training' #YOUR CODE HERE\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.) #YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE\n",
    "# TRAIN GENERATOR.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "#YOUR CODE HERE\n",
    "    TRAINING_DIR,\n",
    "    batch_size=10,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "VALIDATION_DIR = 'datasets/cats-v-dogs/testing'#YOUR CODE HERE\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.) #YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE\n",
    "# VALIDATION GENERATOR.\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "#YOUR CODE HERE\n",
    "    VALIDATION_DIR,\n",
    "    batch_size=10,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Expected Output:\n",
    "# Found ~22500 images belonging to 2 classes.\n",
    "# Found   2500 images belonging to 2 classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1933/2250 [========================>.....] - ETA: 38s - loss: 0.6085 - acc: 0.6777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brian\\pycharmprojects\\tf_certification\\venv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 281s 124ms/step - loss: 0.5969 - acc: 0.6871 - val_loss: 0.5711 - val_acc: 0.7424\n",
      "Epoch 2/2\n",
      "2250/2250 [==============================] - 269s 119ms/step - loss: 0.4926 - acc: 0.7684 - val_loss: 0.5136 - val_acc: 0.7552\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                              epochs=2,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PLOT LOSS AND ACCURACY\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}